---
title: "LangChainAdapter"
description: "CopilotKit Adapter for LangChain"
---

{/* GENERATE-DOCS path=packages/backend/src/lib/langchain-adapter.ts class=LangChainAdapter */}
 
Use this adapter to use LangChain as a backend.
 
```typescript
return copilotKit.response(
  req,
  new LangChainAdapter(async (forwardedProps) => {
    const model = new ChatOpenAI({ modelName: "gpt-4o" });
    return model.stream(forwardedProps.messages, {
      tools: forwardedProps.tools,
    });
  })
);
```
The async handler function can return:
 
- a simple `string` response
- a LangChain stream `IterableReadableStream`
- a LangChain `BaseMessageChunk` object
- a LangChain `AIMessage` object
 
## Example: Anthropic backend
 
```typescript
const copilotKit = new CopilotRuntime();
 
return copilotKit.response(
  req,
  new LangChainAdapter(async (forwardedProps) => {
    const model = new ChatAnthropic({
      temperature: 0.9,
      model: "claude-3-sonnet-20240229",
      // Defaults to process.env.ANTHROPIC_API_KEY,
      // apiKey: "YOUR-API-KEY",
      maxTokens: 1024,
  });
 
  return model.stream(forwardedProps.messages, {
      tools: LangChainAdapter.convertToolsToJsonSchema(forwardedProps.tools),
    });
  }),
);
```

## Constructor

## constructor(private chainFn: (forwardedProps: any) =&gt; Promise&lt;LangChainReturnType&gt;)

To use LangChain as a backend, provide a handler function to the adapter with your custom LangChain logic.

<ResponseField name="chainFn" type="(forwardedProps: any) => Promise<LangChainReturnType>" required>

</ResponseField>

## convertToolsToJsonSchema(tools: any)



<ResponseField name="tools" type="any" required>

</ResponseField>

## getResponse(forwardedProps: any)



<ResponseField name="forwardedProps" type="any" required>

</ResponseField>

